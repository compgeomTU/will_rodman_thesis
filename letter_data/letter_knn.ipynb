{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for Testing K-NN on English Letter Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rq/9zvkr67d2mx07n6md37__xcr0000gn/T/ipykernel_47881/1491859031.py:5: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# standard library\n",
    "import os\n",
    "import json\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "# 3rd party library\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "\n",
    "# local classes\n",
    "os.chdir('../')\n",
    "from TraversalDistance.Graph import Graph\n",
    "from TraversalDistance.FreeSpaceGraph import FreeSpaceGraph\n",
    "from TraversalDistance.KNeighborsClassifier import KNeighborsClassifier\n",
    "os.chdir('letter_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Files into Graph Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_graph(json_data):    \n",
    "    graph = Graph()\n",
    "    graph.name = json_data['gxl']['graph'][0]['$']['id'][0]\n",
    "    \n",
    "    # Extract X, Y coordinates from 'node' elements.\n",
    "    for node_data in json_data['gxl']['graph'][0]['node']:\n",
    "        node_id = int(node_data['$']['id'][1:])\n",
    "        x_coord = float(node_data['attr'][0]['float'][0])\n",
    "        y_coord = float(node_data['attr'][1]['float'][0])\n",
    "        graph.addNode(node_id, x_coord, y_coord)\n",
    "\n",
    "    # Extract edges from 'edge' elements.\n",
    "    for i, edge_data in enumerate(json_data['gxl']['graph'][0]['edge'], 1):\n",
    "        from_node = int(edge_data['$']['from'][1:])\n",
    "        to_node = int(edge_data['$']['to'][1:])\n",
    "        graph.connectTwoNodes(i, from_node, to_node)\n",
    "        \n",
    "    return graph, graph.name\n",
    "\n",
    "# Check if input correct return True for 0 distance between two identical graphs.\n",
    "def is_valid(json_graph):\n",
    "    g1, n1 = json_to_graph(json_graph)\n",
    "    g1.id = 0\n",
    "    g2, n2 = json_to_graph(json_graph)\n",
    "    g2.id = 1\n",
    "    fsg = FreeSpaceGraph(g1, g2, 0.001)\n",
    "    check = fsg.DFSTraversalDist()\n",
    "    return check\n",
    "\n",
    "# Generates dataset inputs and labels for machine learning. \n",
    "# Filters labels to include in dataset. \n",
    "def graph_data():\n",
    "    file_names = os.listdir(\"LOW\")\n",
    "    X, y = list(), list()\n",
    "\n",
    "    for index, file_name in enumerate(file_names):\n",
    "        if file_name.endswith('.json'):\n",
    "            try:         \n",
    "                json_graph = json.load(open(f\"LOW/{file_name}\"))\n",
    "                graph, name = json_to_graph(json_graph)\n",
    "                \n",
    "                if  is_valid(json_graph):\n",
    "                    graph.id = index         \n",
    "                    X.append(graph)\n",
    "                    y.append(name)\n",
    "                else:\n",
    "                    print(f\"Distance failed to compute {file_name}.\")\n",
    "                    \n",
    "                                        \n",
    "            except Exception as error: \n",
    "                print(f\"AssertionError {error}: Fail to parse {file_name}.\")\n",
    "                \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Test/Train Split Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AssertionError 'edge': Fail to parse VP1_0125.json.\n",
      "AssertionError 'edge': Fail to parse LP1_0103.json.\n",
      "AssertionError 'gxl': Fail to parse test.json.\n",
      "AssertionError 'edge': Fail to parse LP1_0136.json.\n",
      "AssertionError 'edge': Fail to parse LP1_0086.json.\n",
      "AssertionError 'edge': Fail to parse LP1_0068.json.\n",
      "AssertionError 'edge': Fail to parse VP1_0086.json.\n",
      "AssertionError 'gxl': Fail to parse validation.json.\n",
      "AssertionError 'gxl': Fail to parse train.json.\n",
      "AssertionError 'edge': Fail to parse IP1_0110.json.\n"
     ]
    }
   ],
   "source": [
    "X, y = graph_data()\n",
    "\n",
    "N, SAMPLE = 100, True\n",
    "\n",
    "if SAMPLE: \n",
    "    X, y = X[:N], y[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes:\n",
      "  T : 9\n",
      "  A : 7\n",
      "  X : 7\n",
      "  H : 7\n",
      "  Y : 9\n",
      "  I : 8\n",
      "  E : 8\n",
      "  N : 7\n",
      "  L : 6\n",
      "  M : 5\n",
      "  V : 6\n",
      "  Z : 5\n",
      "  F : 6\n",
      "  W : 4\n",
      "  K : 6\n"
     ]
    }
   ],
   "source": [
    "print(\"Classes:\")\n",
    "for key , val in Counter(y).items():\n",
    "    print(\" \", key, \":\", val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Traversal Distance K-NN  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model K fold test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_test(X_train, X_test, y_train, y_test, fold):\n",
    "    print(\" \\n *** Stating Fold Test #:\", fold, \"Train len:\", len(y_train), \"Test len:\", len(y_test), \"***\")\n",
    "\n",
    "    model = KNeighborsClassifier(n_neighbors=7, mean='max', left=0, right=3, precision=0.001)  \n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred, log = model.predict(X_test, fold=fold)\n",
    "    \n",
    "    filename = f'logs/knn_log_04_25_fold_{fold}.csv'\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        for i, (y_hat, n_classifications) in enumerate(log):\n",
    "            row = [y_test[i], y_hat] + n_classifications\n",
    "            f.write(','.join(row) + '\\n')\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "        \n",
    "    return precision, recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " *** Stating Fold Test #: 1 Train len: 80 Test len: 20 ***\n",
      "    Fold 1 - Observation 0 of 20\n",
      "    Fold 1 - Observation 1 of 20\n",
      "    Fold 1 - Observation 2 of 20\n",
      "    Fold 1 - Observation 3 of 20\n",
      "    Fold 1 - Observation 4 of 20\n",
      "    Fold 1 - Observation 5 of 20\n",
      "    Fold 1 - Observation 6 of 20\n",
      "    Fold 1 - Observation 7 of 20\n",
      "    Fold 1 - Observation 8 of 20\n",
      "    Fold 1 - Observation 9 of 20\n",
      "    Fold 1 - Observation 10 of 20\n",
      "    Fold 1 - Observation 11 of 20\n",
      "    Fold 1 - Observation 12 of 20\n",
      "    Fold 1 - Observation 13 of 20\n",
      "    Fold 1 - Observation 14 of 20\n",
      "    Fold 1 - Observation 15 of 20\n",
      "    Fold 1 - Observation 16 of 20\n",
      "    Fold 1 - Observation 17 of 20\n",
      "    Fold 1 - Observation 18 of 20\n",
      "    Fold 1 - Observation 19 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " *** Stating Fold Test #: 2 Train len: 80 Test len: 20 ***\n",
      "    Fold 2 - Observation 0 of 20\n",
      "    Fold 2 - Observation 1 of 20\n",
      "    Fold 2 - Observation 2 of 20\n",
      "    Fold 2 - Observation 3 of 20\n",
      "    Fold 2 - Observation 4 of 20\n",
      "    Fold 2 - Observation 5 of 20\n",
      "    Fold 2 - Observation 6 of 20\n",
      "    Fold 2 - Observation 7 of 20\n",
      "    Fold 2 - Observation 8 of 20\n",
      "    Fold 2 - Observation 9 of 20\n",
      "    Fold 2 - Observation 10 of 20\n",
      "    Fold 2 - Observation 11 of 20\n",
      "    Fold 2 - Observation 12 of 20\n",
      "    Fold 2 - Observation 13 of 20\n",
      "    Fold 2 - Observation 14 of 20\n",
      "    Fold 2 - Observation 15 of 20\n",
      "    Fold 2 - Observation 16 of 20\n",
      "    Fold 2 - Observation 17 of 20\n",
      "    Fold 2 - Observation 18 of 20\n",
      "    Fold 2 - Observation 19 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " *** Stating Fold Test #: 3 Train len: 80 Test len: 20 ***\n",
      "    Fold 3 - Observation 0 of 20\n",
      "    Fold 3 - Observation 1 of 20\n",
      "    Fold 3 - Observation 2 of 20\n",
      "    Fold 3 - Observation 3 of 20\n",
      "    Fold 3 - Observation 4 of 20\n",
      "    Fold 3 - Observation 5 of 20\n",
      "    Fold 3 - Observation 6 of 20\n",
      "    Fold 3 - Observation 7 of 20\n",
      "    Fold 3 - Observation 8 of 20\n",
      "    Fold 3 - Observation 9 of 20\n",
      "    Fold 3 - Observation 10 of 20\n",
      "    Fold 3 - Observation 11 of 20\n",
      "    Fold 3 - Observation 12 of 20\n",
      "    Fold 3 - Observation 13 of 20\n",
      "    Fold 3 - Observation 14 of 20\n",
      "    Fold 3 - Observation 15 of 20\n",
      "    Fold 3 - Observation 16 of 20\n",
      "    Fold 3 - Observation 17 of 20\n",
      "    Fold 3 - Observation 18 of 20\n",
      "    Fold 3 - Observation 19 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " *** Stating Fold Test #: 4 Train len: 80 Test len: 20 ***\n",
      "    Fold 4 - Observation 0 of 20\n",
      "    Fold 4 - Observation 1 of 20\n",
      "    Fold 4 - Observation 2 of 20\n",
      "    Fold 4 - Observation 3 of 20\n",
      "    Fold 4 - Observation 4 of 20\n",
      "    Fold 4 - Observation 5 of 20\n",
      "    Fold 4 - Observation 6 of 20\n",
      "    Fold 4 - Observation 7 of 20\n",
      "    Fold 4 - Observation 8 of 20\n",
      "    Fold 4 - Observation 9 of 20\n",
      "    Fold 4 - Observation 10 of 20\n",
      "    Fold 4 - Observation 11 of 20\n",
      "    Fold 4 - Observation 12 of 20\n",
      "    Fold 4 - Observation 13 of 20\n",
      "    Fold 4 - Observation 14 of 20\n",
      "    Fold 4 - Observation 15 of 20\n",
      "    Fold 4 - Observation 16 of 20\n",
      "    Fold 4 - Observation 17 of 20\n",
      "    Fold 4 - Observation 18 of 20\n",
      "    Fold 4 - Observation 19 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " *** Stating Fold Test #: 5 Train len: 80 Test len: 20 ***\n",
      "    Fold 5 - Observation 0 of 20\n",
      "    Fold 5 - Observation 1 of 20\n",
      "    Fold 5 - Observation 2 of 20\n",
      "    Fold 5 - Observation 3 of 20\n",
      "    Fold 5 - Observation 4 of 20\n",
      "    Fold 5 - Observation 5 of 20\n",
      "    Fold 5 - Observation 6 of 20\n",
      "    Fold 5 - Observation 7 of 20\n",
      "    Fold 5 - Observation 8 of 20\n",
      "    Fold 5 - Observation 9 of 20\n",
      "    Fold 5 - Observation 10 of 20\n",
      "    Fold 5 - Observation 11 of 20\n",
      "    Fold 5 - Observation 12 of 20\n",
      "    Fold 5 - Observation 13 of 20\n",
      "    Fold 5 - Observation 14 of 20\n",
      "    Fold 5 - Observation 15 of 20\n",
      "    Fold 5 - Observation 16 of 20\n",
      "    Fold 5 - Observation 17 of 20\n",
      "    Fold 5 - Observation 18 of 20\n",
      "    Fold 5 - Observation 19 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    X_train, X_test = [X[i] for i in train_index], [X[i] for i in test_index]\n",
    "    y_train, y_test = [y[i] for i in train_index], [y[i] for i in test_index]\n",
    "        \n",
    "    precision, recall = k_fold_test(X_train, X_test, y_train, y_test, fold+1)\n",
    "    scores.append((precision, recall))\n",
    "    \n",
    "df = pd.DataFrame(scores, columns=[\"precision\", \"recall\"])\n",
    "df.to_csv('logs/knn_log_04_25.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7046c1012c32b6598d3de8fc9837e48958eb0ce04934b61994dab98503ac34ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
