{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for Testing K-NN on English Letter Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard library\n",
    "import os\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "# 3rd party library\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "\n",
    "# local classes\n",
    "os.chdir('../')\n",
    "from TraversalDistance.Graph import Graph\n",
    "from TraversalDistance.FreeSpaceGraph import FreeSpaceGraph\n",
    "from TraversalDistance.KNeighborsClassifier import KNeighborsClassifier\n",
    "os.chdir('letter_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Files into Graph Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_graph(json_data):    \n",
    "    graph = Graph()\n",
    "    graph.name = json_data['gxl']['graph'][0]['$']['id'][0]\n",
    "    \n",
    "    # Extract X, Y coordinates from 'node' elements.\n",
    "    for node_data in json_data['gxl']['graph'][0]['node']:\n",
    "        node_id = int(node_data['$']['id'][1:])\n",
    "        x_coord = float(node_data['attr'][0]['float'][0])\n",
    "        y_coord = float(node_data['attr'][1]['float'][0])\n",
    "        graph.addNode(node_id, x_coord, y_coord)\n",
    "\n",
    "    # Extract edges from 'edge' elements.\n",
    "    for i, edge_data in enumerate(json_data['gxl']['graph'][0]['edge'], 1):\n",
    "        from_node = int(edge_data['$']['from'][1:])\n",
    "        to_node = int(edge_data['$']['to'][1:])\n",
    "        graph.connectTwoNodes(i, from_node, to_node)\n",
    "        \n",
    "    return graph, graph.name\n",
    "\n",
    "# Check if input correct return True for 0 distance between two identical graphs.\n",
    "def is_valid(json_graph):\n",
    "    g1, n1 = json_to_graph(json_graph)\n",
    "    g1.id = 0\n",
    "    g2, n2 = json_to_graph(json_graph)\n",
    "    g2.id = 1\n",
    "    fsg = FreeSpaceGraph(g1, g2, 0.001)\n",
    "    check = fsg.DFSTraversalDist()\n",
    "    return check\n",
    "\n",
    "# Generates dataset inputs and labels for machine learning. \n",
    "# Filters labels to include in dataset. \n",
    "def graph_data():\n",
    "    file_names = os.listdir(\"LOW\")\n",
    "    X, y = list(), list()\n",
    "\n",
    "    for index, file_name in enumerate(file_names):\n",
    "        if file_name.endswith('.json'):\n",
    "            try:         \n",
    "                json_graph = json.load(open(f\"LOW/{file_name}\"))\n",
    "                graph, name = json_to_graph(json_graph)\n",
    "                \n",
    "                if  is_valid(json_graph):\n",
    "                    graph.id = index         \n",
    "                    X.append(graph)\n",
    "                    y.append(name)\n",
    "                else:\n",
    "                    print(f\"Distance failed to compute {file_name}.\")\n",
    "                    \n",
    "                                        \n",
    "            except Exception as error: \n",
    "                print(f\"AssertionError {error}: Fail to parse {file_name}.\")\n",
    "                \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Test/Train Split Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AssertionError 'edge': Fail to parse VP1_0125.json.\n",
      "AssertionError 'edge': Fail to parse LP1_0103.json.\n",
      "AssertionError 'gxl': Fail to parse test.json.\n",
      "AssertionError 'edge': Fail to parse LP1_0136.json.\n",
      "AssertionError 'edge': Fail to parse LP1_0086.json.\n",
      "AssertionError 'edge': Fail to parse LP1_0068.json.\n",
      "AssertionError 'edge': Fail to parse VP1_0086.json.\n",
      "AssertionError 'gxl': Fail to parse validation.json.\n",
      "AssertionError 'gxl': Fail to parse train.json.\n",
      "AssertionError 'edge': Fail to parse IP1_0110.json.\n"
     ]
    }
   ],
   "source": [
    "X, y = graph_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes:\n",
      "  T : 150\n",
      "  A : 150\n",
      "  X : 150\n",
      "  H : 150\n",
      "  Y : 150\n",
      "  I : 149\n",
      "  E : 150\n",
      "  N : 150\n",
      "  L : 146\n",
      "  M : 150\n",
      "  V : 148\n",
      "  Z : 150\n",
      "  F : 150\n",
      "  W : 150\n",
      "  K : 150\n"
     ]
    }
   ],
   "source": [
    "print(\"Classes:\")\n",
    "for key , val in Counter(y).items():\n",
    "    print(\" \", key, \":\", val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train count: 1794\n",
      "Train count: 449\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "print('Train count:', len(X_train))\n",
    "print('Train count:', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Dataset (for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train, n_test, sample = 50, 50, True\n",
    "\n",
    "if sample: \n",
    "    X_train, X_test, y_train, y_test = X_train[:n_train], X_test[:n_test], y_train[:n_train], y_test[:n_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing and Fitting Traversal Distance K-NN  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=30, mean='max', left=0, right=5, precision=0.01)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observing Model Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'KNeighborsClassifier.predict.<locals>.task'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_pred, log \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/will_rodman_thesis/TraversalDistance/KNeighborsClassifier.py:98\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[0;34m(self, X, n_processes)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool(processes\u001b[38;5;241m=\u001b[39mn_processes) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m---> 98\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m predictions \u001b[38;5;241m=\u001b[39m [item \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m results \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m sublist]\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py:540\u001b[0m, in \u001b[0;36mPool._handle_tasks\u001b[0;34m(taskqueue, put, outqueue, pool, cache)\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 540\u001b[0m     \u001b[43mput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    542\u001b[0m     job, idx \u001b[38;5;241m=\u001b[39m task[:\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/connection.py:205\u001b[0m, in \u001b[0;36m_ConnectionBase.send\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_writable()\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_bytes(\u001b[43m_ForkingPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/reduction.py:51\u001b[0m, in \u001b[0;36mForkingPickler.dumps\u001b[0;34m(cls, obj, protocol)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdumps\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     50\u001b[0m     buf \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO()\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m buf\u001b[38;5;241m.\u001b[39mgetbuffer()\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't pickle local object 'KNeighborsClassifier.predict.<locals>.task'"
     ]
    }
   ],
   "source": [
    "y_pred, log = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'knn_log.csv'\n",
    "\n",
    "with open(filename, 'w') as f:\n",
    "    for i, (y_hat, n_classifications) in enumerate(log):\n",
    "        row = [y_test[i], y_hat] + n_classifications\n",
    "        f.write(','.join(row) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.03111111111111111\n",
      "Recall: 0.15333333333333332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7046c1012c32b6598d3de8fc9837e48958eb0ce04934b61994dab98503ac34ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
