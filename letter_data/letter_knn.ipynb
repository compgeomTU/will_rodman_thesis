{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for Testing K-NN on English Letter Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard library\n",
    "import os\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "# 3rd party library\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "\n",
    "# local classes\n",
    "os.chdir('../')\n",
    "from TraversalDistance.Graph import Graph\n",
    "from TraversalDistance.FreeSpaceGraph import FreeSpaceGraph\n",
    "from TraversalDistance.KNeighborsClassifier import KNeighborsClassifier\n",
    "os.chdir('letter_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Files into Graph Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_graph(json_data):    \n",
    "    graph = Graph()\n",
    "    graph.name = json_data['gxl']['graph'][0]['$']['id'][0]\n",
    "    \n",
    "    # Extract X, Y coordinates from 'node' elements.\n",
    "    for node_data in json_data['gxl']['graph'][0]['node']:\n",
    "        node_id = int(node_data['$']['id'][1:])\n",
    "        x_coord = float(node_data['attr'][0]['float'][0])\n",
    "        y_coord = float(node_data['attr'][1]['float'][0])\n",
    "        graph.addNode(node_id, x_coord, y_coord)\n",
    "\n",
    "    # Extract edges from 'edge' elements.\n",
    "    for i, edge_data in enumerate(json_data['gxl']['graph'][0]['edge'], 1):\n",
    "        from_node = int(edge_data['$']['from'][1:])\n",
    "        to_node = int(edge_data['$']['to'][1:])\n",
    "        graph.connectTwoNodes(i, from_node, to_node)\n",
    "        \n",
    "    return graph, graph.name\n",
    "\n",
    "# Check if input correct return True for 0 distance between two identical graphs.\n",
    "def is_valid(json_graph):\n",
    "    g1, n1 = json_to_graph(json_graph)\n",
    "    g1.id = 0\n",
    "    g2, n2 = json_to_graph(json_graph)\n",
    "    g2.id = 1\n",
    "    fsg = FreeSpaceGraph(g1, g2, 0.001)\n",
    "    check = fsg.DFSTraversalDist()\n",
    "    return check\n",
    "\n",
    "# Generates dataset inputs and labels for machine learning. \n",
    "# Filters labels to include in dataset. \n",
    "def graph_data():\n",
    "    file_names = os.listdir(\"LOW\")\n",
    "    X, y = list(), list()\n",
    "\n",
    "    for index, file_name in enumerate(file_names):\n",
    "        if file_name.endswith('.json'):\n",
    "            try:         \n",
    "                json_graph = json.load(open(f\"LOW/{file_name}\"))\n",
    "                graph, name = json_to_graph(json_graph)\n",
    "                \n",
    "                if  is_valid(json_graph):\n",
    "                    graph.id = index         \n",
    "                    X.append(graph)\n",
    "                    y.append(name)\n",
    "                else:\n",
    "                    print(f\"Distance failed to compute {file_name}.\")\n",
    "                    \n",
    "                                        \n",
    "            except Exception as error: \n",
    "                print(f\"AssertionError {error}: Fail to parse {file_name}.\")\n",
    "                \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Test/Train Split Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AssertionError 'edge': Fail to parse VP1_0125.json.\n",
      "AssertionError 'edge': Fail to parse LP1_0103.json.\n",
      "AssertionError 'gxl': Fail to parse test.json.\n",
      "AssertionError 'edge': Fail to parse LP1_0136.json.\n",
      "AssertionError 'edge': Fail to parse LP1_0086.json.\n",
      "AssertionError 'edge': Fail to parse LP1_0068.json.\n",
      "AssertionError 'edge': Fail to parse VP1_0086.json.\n",
      "AssertionError 'gxl': Fail to parse validation.json.\n",
      "AssertionError 'gxl': Fail to parse train.json.\n",
      "AssertionError 'edge': Fail to parse IP1_0110.json.\n"
     ]
    }
   ],
   "source": [
    "X, y = graph_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes:\n",
      "  T : 150\n",
      "  A : 150\n",
      "  X : 150\n",
      "  H : 150\n",
      "  Y : 150\n",
      "  I : 149\n",
      "  E : 150\n",
      "  N : 150\n",
      "  L : 146\n",
      "  M : 150\n",
      "  V : 148\n",
      "  Z : 150\n",
      "  F : 150\n",
      "  W : 150\n",
      "  K : 150\n"
     ]
    }
   ],
   "source": [
    "print(\"Classes:\")\n",
    "for key , val in Counter(y).items():\n",
    "    print(\" \", key, \":\", val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train count: 1794\n",
      "Train count: 449\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "print('Train count:', len(X_train))\n",
    "print('Train count:', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Dataset (for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train, n_test, sample = 30, 10, False\n",
    "\n",
    "if sample: \n",
    "    X_train, X_test, y_train, y_test = X_train[:n_train], X_test[:n_test], y_train[:n_train], y_test[:n_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing and Fitting Traversal Distance K-NN  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=40, mean='max', left=0, right=3, precision=0.001)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observing Model Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, log = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'knn_log.csv'\n",
    "\n",
    "with open(filename, 'w') as f:\n",
    "    for i, (y_hat, n_classifications) in enumerate(log):\n",
    "        row = [y_test[i], y_hat] + n_classifications\n",
    "        f.write(','.join(row) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7046c1012c32b6598d3de8fc9837e48958eb0ce04934b61994dab98503ac34ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
